<!DOCTYPE html>
<html lang="en">
    <meta http-equiv="content-type" content="text/html;charset=utf-8" />
    <head>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
        <title>VisRecall++: Analysing and Predicting Visualisation Recallability from Gaze Behaviour</title>
        <link rel="stylesheet" media="all" href="./index/css/main_v2.css" />
        <link rel="stylesheet" media="all" href="./wang24_visrecall/css/owl.carousel.min.css" />
        <link rel="stylesheet" media="all" href="./wang24_visrecall/css/owl.theme.default.min.css" />
        <link rel="stylesheet" media="all" href="./wang24_visrecall/css/jquery-ui.min.css" />
        <script src="./wang24_visrecall/js/jquery-3.4.1.min.js"></script>
        <script src="./wang24_visrecall/js/jquery-ui.min.js"></script>
        <script src="./wang24_visrecall/js/fontawesome-5.11.2.js"></script>
        <script src="./wang24_visrecall/js/main.js"></script>
        <script src="./wang24_visrecall/js/owl.carousel.min.js"></script>
        <script src="./wang24_visrecall/js/rot13.js"></script>
		<script src="https://www.w3counter.com/tracker.js?id=150008"></script>
    </head>
    <body class="header header-location">
        <div class="wrapper">
            <!-- header -->
            <div id="unstickyheader" class="unstickyheader">
                <div class="topbar">
                    <div class="container" >
                    </div>
                </div>
            </div>
        </div>
        

        <!-- content -->
        <div class="content">
        <div class="section margin-top-20 margin-bottom-40">
    <div class="container">

        <h3>VisRecall++: Analysing and Predicting Visualisation Recallability from Gaze Behaviour</h3>

        <h4>
        
            <a class="a-int" href="https://www.perceptualui.org/people/wang/">Yao Wang</a>, <a class="a-int" href="https://yuejiang-nj.github.io/">Yue Jiang</a>,
            <a class="a-int" href="https://cranehzm.github.io/">Zhiming Hu</a>,
			<a class="a-int" href="https://www.perceptualui.org/people/ruhdorfer/">Constantin Ruhdorfer</a>,
            <a class="a-int" href="https://www.perceptualui.org/people/bace/">Mihai Bâce</a>,
            <a class="a-int" href="https://www.perceptualui.org/people/bulling/">Andreas Bulling</a>
        </h4>
	
        <h4>        
			<span class="pub_additional_journal">Proceedings of the ACM on Human-Computer Interaction (PACM HCI), 2024, 8(ETRA): 1-18.
			</span>            			
        </h4>

		<hr>
		<img src="./wang24_visrecall/image/teaser.png" style="height:auto; width:1024px;" class="centerContent"><br>
		<i class="centerContent"></i>            
        <hr>
        
        <h4>Abstract</h4>
        Question answering has recently been proposed as a promising means to assess the recallability of information visualisations. However, prior works are yet to study the link between visually encoding a visualisation in memory and recall performance. To fill this gap, we propose VisRecall++ – a novel 40-participant recallability dataset that contains gaze data on 200 visualisations and five question types, such as identifying the title, and finding extreme values.We measured recallability by asking participants questions after they observed the visualisation for 10 seconds.Our analyses reveal several insights, such as saccade amplitude, number of fixations, and fixation duration significantly differ between high and low recallability groups.Finally, we propose GazeRecallNet – a novel computational method to predict recallability from gaze behaviour that outperforms several baselines on this task.Taken together, our results shed light on assessing recallability from gaze behaviour and inform future work on recallability-based visualisation optimisation.
        <hr>

        <h4>Links</h4>
        <div class="pub_links">                        
		<i class="fa fa-file-pdf"></i><p>Paper: <a class="pub_list" href="./wang24_visrecall/pdf/wang24_visrecall.pdf">paper.pdf</a></p>		
		<i class="fa fa-file-pdf"></i><p>Supplementary material: <a class="pub_list" href="./wang24_visrecall/pdf/wang24_visrecall_supp.pdf">supplementary_material.pdf</a></p>
        </div>
		
        <hr>        
        <h4>BibTeX</h4>

<div class="pub_bibtex bg_grey">@article{wang24etra,
	title = {VisRecall++: Analysing and Predicting Visualisation Recallability from Gaze Behaviour},
	author = {Wang, Yao and Jiang, Yue and Hu, Zhiming and Ruhdorfer, Constantin and Bâce, Mihai and Bulling, Andreas},
	year = {2024},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	pages = {1--18},
	volume = {8},
	number = {ETRA}}
</div>

        
    </div>
</div>

        </div>

        <!-- footer -->
        <div id="footer" class="footer-v1">
            
            <div class="copyright custom-copyright">
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <p>
                                
                                <span class="custom-copyright-container">
                                    
                                    Last modified: 18/04/2024
                                </span>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        
    </body>
</html>
