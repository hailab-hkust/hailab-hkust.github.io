<!DOCTYPE html>
<html lang="en">
    <meta http-equiv="content-type" content="text/html;charset=utf-8" />
    <head>
		<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
        <title>HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality</title>
        <link rel="stylesheet" media="all" href="./index/css/main_v2.css"/>
        <link rel="stylesheet" media="all" href="./hu25_haheae/css/owl.carousel.min.css" />
        <link rel="stylesheet" media="all" href="./hu25_haheae/css/owl.theme.default.min.css" />
        <link rel="stylesheet" media="all" href="./hu25_haheae/css/jquery-ui.min.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css">
        <script src="./hu25_haheae/js/jquery-3.4.1.min.js"></script>
        <script src="./hu25_haheae/js/jquery-ui.min.js"></script>
        <script src="./hu25_haheae/js/fontawesome-5.11.2.js"></script>
        <script src="./hu25_haheae/js/main.js"></script>
        <script src="./hu25_haheae/js/owl.carousel.min.js"></script>
        <script src="./hu25_haheae/js/rot13.js"></script>
		<script src="https://www.w3counter.com/tracker.js?id=150008"></script>
    </head>
    <body class="header header-location">
        <div class="wrapper">
            <!-- header -->
            <div id="unstickyheader" class="unstickyheader">
                <div class="topbar">
                    <div class="container" >
                        
                    </div>
                </div>
            </div>
        </div>
		
        <!-- content -->
        <div class="content">
        <div class="section margin-top-20 margin-bottom-40">
    <div class="container">

        <h3>HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality</h3>
		
        <h4>
        
            <a class="a-int" href="https://cranehzm.github.io/">Zhiming Hu</a>, <a class="a-int" href="https://www.perceptualui.org/people/gzhang/">Guanhua Zhang</a>, Zheming Yin, <a class="a-int" href="https://scholar.google.de/citations?user=HO3nVAoAAAAJ&hl=de">Daniel Haeufle</a>, <a class="a-int" href="https://www.imsb.uni-stuttgart.de/team/Schmitt-00006/">Syn Schmitt</a>, <a class="a-int" href="https://www.perceptualui.org/people/bulling/">Andreas Bulling</a>
        </h4>
        <h4>
        
            <span class="pub_additional_journal">IEEE Transactions on Visualization and Computer Graphics (TVCG, oral presentation at ISMAR 2025), 2025, 31(10): 8726 - 8737.
			</span>
        </h4>

		<hr>
		<img src="./hu25_haheae/image/teaser.png" style="height:auto; width:1024px;" class="centerContent"><br>
		<i class="centerContent"></i>            
        <hr>
        		
	<h4>Abstract</h4>
	Human hand and head movements are the most pervasive input modalities in extended reality (XR) and are significant for a wide range of applications. However, prior works on hand and head modelling in XR only explored a single modality or focused on specific applications. We present HaHeAE - a novel self-supervised method for learning generalisable joint representations of hand and head movements in XR. At the core of our method is an autoencoder (AE) that uses a graph convolutional network-based semantic encoder and a diffusion-based stochastic encoder to learn the joint semantic and stochastic representations of hand-head movements. It also features a diffusion-based decoder to reconstruct the original signals. Through extensive evaluations on three public XR datasets, we show that our method 1) significantly outperforms commonly used self-supervised methods by up to 74.1% in terms of reconstruction quality and is generalisable across users, activities, and XR environments, 2) enables new applications, including interpretable hand-head cluster identification and variable hand-head movement generation, and 3) can serve as an effective feature extractor for downstream tasks. Together, these results demonstrate the effectiveness of our method and underline the potential of self-supervised methods for jointly modelling hand-head behaviours in extended reality.		
	<hr>
		
	<h4>Links</h4>
	<div class="pub_links">
					
		<svg class="svg-inline--fa fa-file-pdf fa-w-12" aria-hidden="true" focusable="false" data-prefix="fa" data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512" data-fa-i2svg=""><path fill="currentColor" d="M181.9 256.1c-5-16-4.9-46.9-2-46.9 8.4 0 7.6 36.9 2 46.9zm-1.7 47.2c-7.7 20.2-17.3 43.3-28.4 62.7 18.3-7 39-17.2 62.9-21.9-12.7-9.6-24.9-23.4-34.5-40.8zM86.1 428.1c0 .8 13.2-5.4 34.9-40.2-6.7 6.3-29.1 24.5-34.9 40.2zM248 160h136v328c0 13.3-10.7 24-24 24H24c-13.3 0-24-10.7-24-24V24C0 10.7 10.7 0 24 0h200v136c0 13.2 10.8 24 24 24zm-8 171.8c-20-12.2-33.3-29-42.7-53.8 4.5-18.5 11.6-46.6 6.2-64.2-4.7-29.4-42.4-26.5-47.8-6.8-5 18.3-.4 44.1 8.1 77-11.6 27.6-28.7 64.6-40.8 85.8-.1 0-.1.1-.2.1-27.1 13.9-73.6 44.5-54.5 68 5.6 6.9 16 10 21.5 10 17.9 0 35.7-18 61.1-61.8 25.8-8.5 54.1-19.1 79-23.2 21.7 11.8 47.1 19.5 64 19.5 29.2 0 31.2-32 19.7-43.4-13.9-13.6-54.3-9.7-73.6-7.2zM377 105L279 7c-4.5-4.5-10.6-7-17-7h-6v128h128v-6.1c0-6.3-2.5-12.4-7-16.9zm-74.1 255.3c4.1-2.7-2.5-11.9-42.8-9 37.1 15.8 42.8 9 42.8 9z"></path></svg><p>Paper: <a class="pub_list" href="./hu25_haheae/pdf/hu25_haheae.pdf">paper.pdf</a></p>
		<i class="fa fa-file-pdf"></i>&nbsp;Supplementary materials: <a class="pub_list" href="./hu25_haheae/pdf/hu25_haheae_supplementary_material.pdf">supplementary_material.pdf</a></p>
		<i class="fa fa-file-powerpoint"></i>&nbsp; Slides: <a class="pub_list" href="./hu25_haheae/ppt/hu25_haheae.pdf">slides.pdf</a></p>
		<i class="fa fa-code"></i>&nbsp;Code: <a class="a-text-ext" href="https://github.com/CraneHzm/HaHeAE">code</a></p>
	</div>
	
	<hr>

	<h4>BibTeX</h4>
	
<div class="pub_bibtex bg_grey">@article{hu25haheae,
	author={Hu, Zhiming and Zhang, Guanhua and Yin, Zheming and Haeufle, Daniel and Schmitt, Syn and Bulling, Andreas},
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={HaHeAE: Learning Generalisable Joint Representations of Human Hand and Head Movements in Extended Reality}, 
	year={2025},
	volume={31},
	number={10},
	pages={8726--8737},
	doi={10.1109/TVCG.2025.3576999}}	
</div>
    </div>
</div>
        </div>

        <!-- footer -->
        <div id="footer" class="footer-v1">
            
            <div class="copyright custom-copyright">
                <div class="container">
                    <div class="row">
                        <div class="col-md-6">
                            <p>
                                <span class="custom-copyright-container">
                                    Last modified: 03/06/2025
                                </span>
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        
    </body>
</html>